{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jigsaw_TPU_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rMtEVAIXsfw",
        "colab_type": "text"
      },
      "source": [
        "# Install torch_xla: enabling PyTorch on Google TPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Jq3q2lXvtA",
        "colab_type": "code",
        "outputId": "b609c658-62f2-403f-da1c-b58d8517d6e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
        " \n",
        " \n",
        "def install_stable():\n",
        " VERSION = \"20200516\"  #@param [\"1.5\" , \"20200516\", \"nightly\"]\n",
        " !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        " !python pytorch-xla-env-setup.py --version $VERSION\n",
        "\n",
        "\n",
        "install_stable()\n",
        "\n",
        "import torch \n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  4264  100  4264    0     0  49581      0 --:--:-- --:--:-- --:--:-- 49581\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200516 ...\n",
            "Uninstalling torch-1.5.0+cu101:\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "  Successfully uninstalled torch-1.5.0+cu101\n",
            "Uninstalling torchvision-0.6.0+cu101:\n",
            "  Successfully uninstalled torchvision-0.6.0+cu101\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 91.0 MiB/ 91.0 MiB]                                                \n",
            "Operation completed over 1 objects/91.0 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][119.8 MiB/119.8 MiB]                                                \n",
            "Operation completed over 1 objects/119.8 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.3 MiB/  2.3 MiB]                                                \n",
            "Operation completed over 1 objects/2.3 MiB.                                      \n",
            "Processing ./torch-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200516) (0.16.0)\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.6.0a0+83df3be\n",
            "Processing ./torch_xla-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "Successfully installed torch-xla-1.6+2191422\n",
            "Processing ./torchvision-nightly+20200516-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.18.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (7.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200516) (1.6.0a0+83df3be)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200516) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.7.0a0+348dd5a\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libomp5\n",
            "0 upgraded, 1 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 234 kB of archives.\n",
            "After this operation, 774 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libomp5 amd64 5.0.1-1 [234 kB]\n",
            "Fetched 234 kB in 1s (379 kB/s)\n",
            "Selecting previously unselected package libomp5:amd64.\n",
            "(Reading database ... 144467 files and directories currently installed.)\n",
            "Preparing to unpack .../libomp5_5.0.1-1_amd64.deb ...\n",
            "Unpacking libomp5:amd64 (5.0.1-1) ...\n",
            "Setting up libomp5:amd64 (5.0.1-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "1.6.0a0+83df3be\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-ubRC8Ahuoq",
        "colab_type": "text"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X26PHc-TSpRP",
        "colab_type": "text"
      },
      "source": [
        "Link Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFHhdmzMR4Qn",
        "colab_type": "code",
        "outputId": "9ed3713d-73dd-4549-a8a6-516132debe4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fht63M_b3HPB",
        "colab_type": "text"
      },
      "source": [
        "Install transformers from huggingface"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56fWXC8fdHRH",
        "colab_type": "code",
        "outputId": "7fcdd4e5-0010-4cba-aa37-04f48f8facc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |████████████████████████████████| 675kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.4)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 18.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 26.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 32.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=784e157f7380a49afa05c09821b527432dbf4267ab7558c796aab8db9fa3864e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xlbk49mXT_2",
        "colab_type": "text"
      },
      "source": [
        "# config.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsdDYeWbXO-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "\n",
        "from sklearn import metrics\n",
        "from transformers import AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class config:\n",
        "    MAX_LEN = 192\n",
        "    TRAIN_BATCH_SIZE = 64\n",
        "    VALID_BATCH_SIZE = 4\n",
        "    EPOCHS = 2\n",
        "    LEARNING_RATE = 1e-6\n",
        "    BERT_PATH = \"/content/gdrive/My Drive/bert-base-multilingual-uncased/\"\n",
        "    MODEL_PATH = \"/content/gdrive/My Drive/bert_model.bin\"\n",
        "    TOKENIZER = transformers.BertTokenizer.from_pretrained(\n",
        "        BERT_PATH,\n",
        "        do_lower_case=True\n",
        "    )\n",
        "    JIGSAW_DATA_PATH = \"/content/gdrive/My Drive/\"\n",
        "    TRAINING_FILE_1 = os.path.join(\n",
        "        JIGSAW_DATA_PATH, \n",
        "        \"jigsaw-toxic-comment-train.csv\"\n",
        "    )\n",
        "    TRAINING_FILE_2 = os.path.join(\n",
        "        JIGSAW_DATA_PATH, \n",
        "        \"jigsaw-unintended-bias-train.csv\"\n",
        "    )\n",
        "    VALIDATION_FILE = os.path.join(\n",
        "        JIGSAW_DATA_PATH, \n",
        "        \"validation.csv\"\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IslfGoq_h4zA",
        "colab_type": "text"
      },
      "source": [
        "# dataset.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTtjN0F7ZCDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class JigsawTraining:\n",
        "    def __init__(self, comment_text, targets, config):\n",
        "        self.comment_text = comment_text\n",
        "        self.tokenizer = config.TOKENIZER\n",
        "        self.max_length = config.MAX_LEN\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.comment_text)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        comment_text = str(self.comment_text[item])\n",
        "        comment_text = \" \".join(comment_text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            comment_text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "        )\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        \n",
        "        padding_length = self.max_length - len(ids)\n",
        "        \n",
        "        ids = ids + ([0] * padding_length)\n",
        "        mask = mask + ([0] * padding_length)\n",
        "        token_type_ids = token_type_ids + ([0] * padding_length)\n",
        "        \n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[item], dtype=torch.float)\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4YaEP5SiVel",
        "colab_type": "text"
      },
      "source": [
        "# model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvRBD5VUiYhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class JigsawModel(nn.Module):\n",
        "    def __init__(self, bert_path):\n",
        "        super(JigsawModel, self).__init__()\n",
        "        self.bert_path = bert_path\n",
        "        self.bert = transformers.BertModel.from_pretrained(self.bert_path)\n",
        "        self.bert_drop = nn.Dropout(0.5)\n",
        "        self.out = nn.Linear(768 * 2, 1)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            ids,\n",
        "            mask,\n",
        "            token_type_ids\n",
        "    ):\n",
        "        out_1, out_2 = self.bert(\n",
        "            ids,\n",
        "            attention_mask=mask,\n",
        "            token_type_ids=token_type_ids)\n",
        "        \n",
        "        apool = torch.mean(out_1, 1)\n",
        "        mpool, _ = torch.max(out_1, 1)\n",
        "        cat = torch.cat((apool, mpool), 1)\n",
        "\n",
        "        bo = self.bert_drop(cat)\n",
        "        p2 = self.out(bo)\n",
        "        return p2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub1rPkOuUO1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MX = JigsawModel(config.BERT_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sx_K_NO1ia5c",
        "colab_type": "text"
      },
      "source": [
        "# engine.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78a75fXLieUg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n",
        "\n",
        "\n",
        "def train_fn(data_loader, model, optimizer, device, scheduler):\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    model.train()\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    for bi, d in enumerate(data_loader):\n",
        "        ids = d[\"ids\"]\n",
        "        token_type_ids = d[\"token_type_ids\"]\n",
        "        mask = d[\"mask\"]\n",
        "        targets = d[\"targets\"]\n",
        "\n",
        "        ids = ids.to(device, dtype=torch.long)\n",
        "        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "        mask = mask.to(device, dtype=torch.long)\n",
        "        targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            ids=ids,\n",
        "            mask=mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        train_losses.append(loss)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        xm.optimizer_step(optimizer)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        if bi % 100 == 0:\n",
        "            print(f'[xla:{xm.get_ordinal()}]: bi={bi}, train loss={loss}')\n",
        "\n",
        "    return train_losses\n",
        "\n",
        "\n",
        "def eval_fn(data_loader, model, device):\n",
        "    import torch_xla.core.xla_model as xm\n",
        "    model.eval()\n",
        "\n",
        "    val_losses = []\n",
        "\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for bi, d in enumerate(data_loader):\n",
        "            ids = d[\"ids\"]\n",
        "            token_type_ids = d[\"token_type_ids\"]\n",
        "            mask = d[\"mask\"]\n",
        "            targets = d[\"targets\"]\n",
        "\n",
        "            ids = ids.to(device, dtype=torch.long)\n",
        "            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n",
        "            mask = mask.to(device, dtype=torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "\n",
        "            outputs = model(\n",
        "                ids=ids,\n",
        "                mask=mask,\n",
        "                token_type_ids=token_type_ids\n",
        "            )\n",
        "\n",
        "            loss = loss_fn(outputs, targets)\n",
        "           \n",
        "            val_losses.append(loss)\n",
        "\n",
        "            if bi % 100 == 0:\n",
        "                print(f'[xla:{xm.get_ordinal()}]: bi={bi}, valid loss={loss}')\n",
        "\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
        "\n",
        "    return fin_outputs, fin_targets, val_losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHzeDeIziisj",
        "colab_type": "text"
      },
      "source": [
        "# train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd0MbPe8ilrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train1 = pd.read_csv(\n",
        "    config.TRAINING_FILE_1, \n",
        "    usecols=[\"comment_text\", \"toxic\"]\n",
        ").fillna(\"none\")\n",
        "\n",
        "df_train2 = pd.read_csv(\n",
        "    config.TRAINING_FILE_2, \n",
        "    usecols=[\"comment_text\", \"toxic\"]\n",
        ").fillna(\"none\")\n",
        "\n",
        "df_valid = pd.read_csv(config.VALIDATION_FILE)\n",
        "\n",
        "df_train = pd.concat([df_train1, df_train2], axis=0).reset_index(drop=True)\n",
        "# df_train = df_train.sample(frac=1).reset_index(drop=True).head(200000)\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True).head(1000000)\n",
        "\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_valid = df_valid.reset_index(drop=True)\n",
        "\n",
        "train_targets = df_train.toxic.values\n",
        "valid_targets = df_valid.toxic.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBgQqbLfjPKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "def run():\n",
        "    train_dataset = JigsawTraining(\n",
        "        comment_text=df_train.comment_text.values,\n",
        "        targets=train_targets,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          train_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=True)\n",
        "\n",
        "    train_data_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config.TRAIN_BATCH_SIZE,\n",
        "        sampler=train_sampler,\n",
        "        drop_last=True,\n",
        "        num_workers=2\n",
        "    )\n",
        "\n",
        "    valid_dataset = JigsawTraining(\n",
        "        comment_text=df_valid.comment_text.values,\n",
        "        targets=valid_targets,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    valid_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "          valid_dataset,\n",
        "          num_replicas=xm.xrt_world_size(),\n",
        "          rank=xm.get_ordinal(),\n",
        "          shuffle=False)\n",
        "\n",
        "    valid_data_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=config.VALID_BATCH_SIZE,\n",
        "        sampler=valid_sampler,\n",
        "        drop_last=False,\n",
        "        num_workers=1\n",
        "    )\n",
        "\n",
        "    device = xm.xla_device()\n",
        "    model = MX.to(device)\n",
        "    \n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_parameters = [\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if not any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ], \n",
        "            'weight_decay': 0.001\n",
        "        },\n",
        "        {\n",
        "            'params': [\n",
        "                p for n, p in param_optimizer if any(\n",
        "                    nd in n for nd in no_decay\n",
        "                )\n",
        "            ],\n",
        "            'weight_decay': 0.0\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    num_train_steps = int(\n",
        "        len(df_train) / config.TRAIN_BATCH_SIZE / xm.xrt_world_size() * config.EPOCHS\n",
        "    )\n",
        "    optimizer = AdamW(\n",
        "        optimizer_parameters, \n",
        "        lr=config.LEARNING_RATE * xm.xrt_world_size()\n",
        "    )\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=num_train_steps\n",
        "    )\n",
        "\n",
        "    best_auc = 0\n",
        "    for epoch in range(config.EPOCHS):\n",
        "        start_time = time.time()\n",
        "\n",
        "        para_loader = pl.ParallelLoader(train_data_loader, [device])\n",
        "        train_losses = train_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            optimizer, \n",
        "            device, \n",
        "            scheduler\n",
        "        )\n",
        "        \n",
        "        para_loader = pl.ParallelLoader(valid_data_loader, [device])\n",
        "        outputs, targets, val_losses = eval_fn(\n",
        "            para_loader.per_device_loader(device), \n",
        "            model, \n",
        "            device\n",
        "        )\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        \"\"\"        \n",
        "        plt.plot(train_losses, label=\"Training loss\")\n",
        "        plt.plot(val_losses, label=\"Validation loss\")\n",
        "        plt.legend()\n",
        "        plt.title(\"Losses\")\n",
        "        plt.show();\n",
        "        \"\"\"        \n",
        "\n",
        "        targets = np.array(targets) >= 0.5\n",
        "        auc = metrics.roc_auc_score(targets, outputs)\n",
        "\n",
        "        print(f'[xla:{xm.get_ordinal()}]: AUC={auc}')\n",
        "        if auc > best_auc:\n",
        "            xm.save(model.state_dict(), config.MODEL_PATH)\n",
        "            best_auc = auc\n",
        "        \n",
        "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBt1_pijjSZ7",
        "colab_type": "text"
      },
      "source": [
        "Multi-processing wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZBKeYI3jVBx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _mp_fn(rank, flags):\n",
        "    torch.set_default_tensor_type('torch.FloatTensor')\n",
        "    a = run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWWFJi58jWI9",
        "colab_type": "text"
      },
      "source": [
        "Process spawner for training on TPUs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sE_4NQIjaN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FLAGS={}\n",
        "xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}